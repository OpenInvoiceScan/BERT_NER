{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo para el reconocimiento de Facturas\n",
    "\n",
    "En este notebook, realizamos el entrenamiento de BERT (Bidirectional Encoder Representations from Transformers), un modelo para tareas de Procesamiento de Lenguaje Natural (NLP).\n",
    "\n",
    "En este caso, lo estamos utilizando para tareas de etiquetado en un texto de entrada, que en este caso es el OCR de una factura. Esto nos permitirá extraer los datos para luego pasarlos automáticamente a un formato JSON y hacer el procesamiento de documentos mucho más accesible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Bibliotecas\n",
    "\n",
    "- `import torch`: Importa la biblioteca PyTorch, un marco de trabajo de aprendizaje profundo.\n",
    "- `from torch.utils.data import Dataset, DataLoader`: Importa la clase `Dataset` y `DataLoader` de PyTorch, que son útiles para manejar conjuntos de datos durante el entrenamiento.\n",
    "- `from transformers import BertTokenizer, BertForTokenClassification, BertTokenizerFast`: Importa las clases y funciones necesarias de la biblioteca Transformers de Hugging Face, específicamente para el modelo BERT y su tokenizador.\n",
    "- `from torch.optim import AdamW`: Importa el optimizador AdamW de PyTorch, que se utiliza comúnmente para optimizar los modelos de aprendizaje profundo.\n",
    "- `from sklearn.model_selection import train_test_split`: Importa la función `train_test_split` de scikit-learn, que se utiliza para dividir un conjunto de datos en conjuntos de entrenamiento y prueba.\n",
    "- `from sklearn.preprocessing import LabelEncoder`: Importa la clase `LabelEncoder` de scikit-learn, que se utiliza para codificar etiquetas de clase como valores numéricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, BertTokenizerFast\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Modelo\n",
    "En este caso estamos usando la variante multilenguaje con distinción entre mayúsculas y minúsculas, esto nos puede ayudar con la detección de nombres que empiezan en mayúscula por ejemplo. Además definimos un codificador de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'google-bert/bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "label_encoder = LabelEncoder()\n",
    "labels = [\n",
    "    \"O\",  # Para tokens que no son parte de ninguna entidad nombrada\n",
    "    \"B-invoice_id\", \"I-invoice_id\",\n",
    "    \"B-issue_date\", \"I-issue_date\",\n",
    "    \"B-due_date\", \"I-due_date\",\n",
    "    \"B-issuer_name\", \"I-issuer_name\",\n",
    "    \"B-issuer_address\", \"I-issuer_address\",\n",
    "    \"B-issuer_phone\",\n",
    "    \"B-issuer_email\",\n",
    "    \"B-issuer_tax_id\",\n",
    "    \"B-recipient_name\", \"I-recipient_name\",\n",
    "    \"B-recipient_address\", \"I-recipient_address\",\n",
    "    \"B-recipient_phone\",\n",
    "    \"B-recipient_email\",\n",
    "    \"B-recipient_tax_id\",\n",
    "    \"B-item_description\", \"I-item_description\",\n",
    "    \"B-item_quantity\",\n",
    "    \"B-item_unit_price\",\n",
    "    \"B-item_total\",\n",
    "    \"B-subtotal\",\n",
    "    \"B-tax_description\", \"I-tax_description\",\n",
    "    \"B-tax_percentage\",\n",
    "    \"B-tax_amount\",\n",
    "    \"B-total\",\n",
    "    \"B-payment_method\",\n",
    "    \"UNK\"\n",
    "]\n",
    "\n",
    "label_encoder.fit(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de Función para Alinear Tokens y Etiquetas\n",
    "\n",
    "Se define una función llamada `align_tokens_and_labels` que toma como entrada un texto y las etiquetas asociadas. La función tokeniza el texto utilizando el tokenizador previamente definido, luego alinea las etiquetas con los tokens tokenizados y las convierte en valores numéricos utilizando el codificador de etiquetas.\n",
    "\n",
    "### Definición de Clase `InvoiceDataset`\n",
    "\n",
    "Se define una clase llamada `InvoiceDataset` que hereda de la clase `Dataset`. Esta clase se utiliza para representar un conjunto de datos de facturas. En el método `__init__`, se inicializan los textos y las etiquetas de las facturas, así como la longitud máxima permitida para el texto tokenizado. El método `__len__` devuelve la longitud del conjunto de datos, y el método `__getitem__` obtiene un ejemplo del conjunto de datos. Dentro de este método, se tokeniza el texto y se alinean las etiquetas utilizando la función `align_tokens_and_labels`, y luego se devuelve un diccionario con los IDs de entrada, la máscara de atención y las etiquetas, todos convertidos a tensores de PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens_and_labels(text,tags):\n",
    "    encoded_input = tokenizer(text, is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    encoded_as_text = tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"])\n",
    "\n",
    "    word_ids = encoded_input.word_ids()\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(word_ids)):\n",
    "        if word_ids[i] is None:\n",
    "            labels.append('UNK')\n",
    "        else:\n",
    "            labels.append(tags[word_ids[i]])\n",
    "    \n",
    "    labels = label_encoder.transform(labels)\n",
    "    \n",
    "    return {\n",
    "        \"encoded_input\": encoded_input, \n",
    "        \"encoded_labels\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class InvoiceDataset(Dataset):\n",
    "    def __init__(self, texts, tags, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        tags = self.tags[idx]\n",
    "\n",
    "\n",
    "        # Tokenización y alineación de etiquetas\n",
    "        result = align_tokens_and_labels(text, tags)\n",
    "        encoding = result[\"encoded_input\"]\n",
    "        labels = result[\"encoded_labels\"]\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(encoding['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(encoding['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "texts = []  # Lista de textos de factura\n",
    "tags = []  # Lista de etiquetas (cada etiqueta es una lista de ids de etiquetas)\n",
    "\n",
    "def load_tags(file_path):\n",
    "    tags = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Dividir la línea por ' -> ' y tomar el segundo elemento, que es la etiqueta\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                tags.append(parts[1])  # Agrega la etiqueta a la lista\n",
    "    return tags\n",
    "\n",
    "def load_text(file_path):\n",
    "    texts = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Dividir la línea por ' -> ' y tomar el segundo elemento, que es la etiqueta\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                texts.append(parts[0])  # Agrega la etiqueta a la lista\n",
    "    return texts\n",
    "\n",
    "tags = []\n",
    "for i in range(1000):  # Ajusta el rango según la cantidad de facturas\n",
    "    tags.append(load_tags(f'dataset_output/train/train{i}.tokens'))\n",
    "    texts.append(load_text(f'dataset_output/train/train{i}.tokens'))\n",
    "\n",
    "# Crear el dataset y dataloader\n",
    "dataset = InvoiceDataset(texts, tags)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 85245, 11465, 131, 108, 50461, 32168, 11305, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[33, 32, 32, 32, 1, 1, 1, 1, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33]\n",
      "[CLS] ['UNK']\n",
      "Fact ['O']\n",
      "##ura ['O']\n",
      ": ['O']\n",
      "# ['B-invoice_id']\n",
      "562 ['B-invoice_id']\n",
      "##48 ['B-invoice_id']\n",
      "##7 ['B-invoice_id']\n",
      "[SEP] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n",
      "[PAD] ['UNK']\n"
     ]
    }
   ],
   "source": [
    "#Probar a tokenizar un texto para ver su longitud tokenizada\n",
    "\n",
    "print(dataset[0]['input_ids'].tolist())\n",
    "print(dataset[0]['labels'].tolist())\n",
    "\n",
    "ids = tokenizer.convert_ids_to_tokens(dataset[0]['input_ids'])\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    print(ids[i], label_encoder.inverse_transform([dataset[0]['labels'][i].item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, tags, test_size=0.1)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataset = InvoiceDataset(train_texts, train_labels)\n",
    "val_dataset = InvoiceDataset(val_texts, val_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Determinar el dispositivo a usar (GPU si está disponible, de lo contrario CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Modelo\n",
    "model = BertForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(labels))\n",
    "model.to(device)  # Mover el modelo a la GPU si está disponible\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        # Mover los datos al dispositivo correcto\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()  # Pone el modelo en modo evaluación\n",
    "    total_accuracy = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)  # Obtén la clase predicha para cada token\n",
    "\n",
    "            # Ignorar tokens con etiquetas -100 (usadas en algunos datasets para ignorar ciertos tokens)\n",
    "            mask = (labels != -100)\n",
    "            correct_predictions = (predictions == labels) & mask\n",
    "            total_accuracy += correct_predictions.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "    return total_accuracy / total_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3050186497414798, Val Accuracy: 98.92%\n",
      "Epoch 2, Train Loss: 0.020932163659944734, Val Accuracy: 99.96%\n",
      "Epoch 3, Train Loss: 0.005056238773410761, Val Accuracy: 99.99%\n",
      "Epoch 4, Train Loss: 0.0027228838473607876, Val Accuracy: 100.00%\n",
      "Epoch 5, Train Loss: 0.0018284853508662993, Val Accuracy: 100.00%\n",
      "Epoch 6, Train Loss: 0.001352987572575499, Val Accuracy: 99.99%\n",
      "Epoch 7, Train Loss: 0.001185653043037231, Val Accuracy: 100.00%\n",
      "Epoch 8, Train Loss: 0.0009847740071982278, Val Accuracy: 100.00%\n",
      "Epoch 9, Train Loss: 0.0010203274901321702, Val Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 34\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "for epoch in range(30):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    val_accuracy = evaluate(model, val_loader)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss}, Val Accuracy: {val_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=34, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Pon el modelo en modo evaluación\n",
    "model.to(device)  # Asegúrate de que el modelo esté en el dispositivo correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Asumiendo que 'MODEL_NAME' es el nombre del modelo BERT que usaste\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "text = \"\"\"\n",
    "Factura\n",
    "FH600301\n",
    "\n",
    "Fecha de emisión: 2024-03-11\n",
    "Fecha de vencimiento: 2024-04-15\n",
    "\n",
    "Datos del Emisor: Datos del Receptor:\n",
    "Williams, York and Schwartz Katrina Fritz\n",
    "540 Strong Green North April, AK 08628 0936 Butler Villages Apt. 228 Williamhaven, NY 24061\n",
    "2803178625 +1-905-539-8849x13583\n",
    "hamptondanielle(O griffin.com mariah650 gmail.com\n",
    "vsP770FmMb986 arF309WLD229\n",
    "Descripción Cantidad Precio Unitario Total\n",
    "expedite 24/7 systems 9 80.86 727.74\n",
    "orchestrate web-enabled models 7 65.31 457.17\n",
    "drive enterprise technologies 10 46.53 465.3\n",
    "\n",
    "Subtotal: 1650.21\n",
    "VAT (16%): 264.03\n",
    "Total: 1914.24\n",
    "\n",
    "Método de pago: PayPal\n",
    "\"\"\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "input_ids = encoded_input['input_ids'].to(device)\n",
    "attention_mask = encoded_input['attention_mask'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # No necesitas calcular gradientes aquí\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Aplicar softmax para obtener probabilidades\n",
    "probabilities = F.softmax(logits, dim=-1)\n",
    "predictions = torch.argmax(probabilities, dim=-1)\n",
    "predicted_labels = [label_encoder.inverse_transform([label.item()])[0] for label in predictions[0]]\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Factura FH600301 Fechadeemisión: 2024-03-11 Fechadevencimiento: 2024-04-15 DatosdelEmisor:DatosdelReceptor: Williams, YorkandSchwartz KatrinaFritz 540StrongGreenNorthApril,AK086280936ButlerVillagesApt.228Williamhaven,NY24061 2803178625 + 1-905 -539-8849x13583 hamptondanielle(Ogriffin.commariah650gmail.com vsP770FmMb986arF309WLD229 DescripciónCantidadPrecioUnitarioTotal expedite 24/7systems 9 80.86 727.74 orchestrate web-enabledmodels 7 65.31 457.17 drive enterprisetechnologies 10 46.53 465.3 Subtotal: 1650.21 VAT (16%) : 264.03 Total: 1914.24 Métododepago: PayPal [SEP]\n",
      "[CLS] -> UNK\n",
      "Factura -> O\n",
      "FH600301 -> B-invoice_id\n",
      "Fechadeemisión: -> O\n",
      "2024-03-11 -> B-issue_date\n",
      "Fechadevencimiento: -> O\n",
      "2024-04-15 -> B-due_date\n",
      "DatosdelEmisor:DatosdelReceptor: -> O\n",
      "Williams, YorkandSchwartz KatrinaFritz 540StrongGreenNorthApril,AK086280936ButlerVillagesApt.228Williamhaven,NY24061 -> B-issuer_name\n",
      "2803178625 -> B-issuer_phone\n",
      "+ -> B-recipient_phone\n",
      "1-905 -> B-issuer_phone\n",
      "-539-8849x13583 -> B-recipient_phone\n",
      "hamptondanielle(Ogriffin.commariah650gmail.com -> B-recipient_email\n",
      "vsP770FmMb986arF309WLD229 -> B-recipient_tax_id\n",
      "DescripciónCantidadPrecioUnitarioTotal -> O\n",
      "expedite 24/7systems -> B-item_description\n",
      "9 -> B-item_quantity\n",
      "80.86 -> B-item_unit_price\n",
      "727.74 -> B-item_total\n",
      "orchestrate web-enabledmodels -> B-item_description\n",
      "7 -> B-item_quantity\n",
      "65.31 -> B-item_unit_price\n",
      "457.17 -> B-item_total\n",
      "drive enterprisetechnologies -> B-item_description\n",
      "10 -> B-item_quantity\n",
      "46.53 -> B-item_unit_price\n",
      "465.3 -> B-item_total\n",
      "Subtotal: -> O\n",
      "1650.21 -> B-subtotal\n",
      "VAT -> B-tax_description\n",
      "(16%) -> B-tax_percentage\n",
      ": -> O\n",
      "264.03 -> B-tax_amount\n",
      "Total: -> O\n",
      "1914.24 -> B-total\n",
      "Métododepago: -> O\n",
      "PayPal -> B-payment_method\n",
      "[SEP] -> UNK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = tokenizer.convert_tokens_to_string(tokens)\n",
    "print(text)\n",
    "\n",
    "def clean_token(tokens, labels):\n",
    "    cleaned_tokens = []\n",
    "    cleaned_labels = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if token.startswith(\"##\"):\n",
    "            cleaned_tokens[-1] = cleaned_tokens[-1] +  token[2:]\n",
    "        else:\n",
    "            cleaned_tokens.append(token)\n",
    "            cleaned_labels.append(label)\n",
    "    return cleaned_tokens, cleaned_labels\n",
    "\n",
    "def concat_consecutive_tags(tokens, labels):\n",
    "    cleaned_tokens = []\n",
    "    cleaned_labels = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if len(cleaned_labels) > 0 and cleaned_labels[-1] == label:\n",
    "            cleaned_tokens[-1] = cleaned_tokens[-1]  +  token\n",
    "        else:\n",
    "            cleaned_tokens.append(token)\n",
    "            cleaned_labels.append(label)\n",
    "    return cleaned_tokens, cleaned_labels\n",
    "\n",
    "def concat_continue_labels_BI(tokens, labels):\n",
    "    cleaned_tokens = []\n",
    "    cleaned_labels = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if len(cleaned_labels) > 0 and label.startswith(\"I-\"):\n",
    "            cleaned_tokens[-1] = cleaned_tokens[-1] + \" \" +  token\n",
    "        else:\n",
    "            cleaned_tokens.append(token)\n",
    "            cleaned_labels.append(label)\n",
    "    return cleaned_tokens, cleaned_labels\n",
    "\n",
    "tokens, predicted_labels = clean_token(tokens, predicted_labels)\n",
    "tokens, predicted_labels = concat_consecutive_tags(tokens, predicted_labels)\n",
    "tokens, predicted_labels = concat_continue_labels_BI(tokens, predicted_labels)\n",
    "\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f'{token} -> {label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
